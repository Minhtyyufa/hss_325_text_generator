Freud describes the uncanny as something familiar that we’ve repressed coming back into the light. For the feeling of uncanny to occur, something we experience must be perceived as reality and cause dissonance in what we know to be real. This ties perfectly into The Sandman, a creature that takes away the main form of perception, the eyes. The story itself is all about what is real and not real. Nathanael spends the entire time confused about what is real and what is not real. He confuses Olimpia for a human and doesn’t know whether his own fiance is real. He’s haunted by never really being certain about anything, leading to his eventual demise. What really got me thinking is Freud’s beliefs about what the uncanny means. His definition implies that when we see something truly novel we respond with an uncomfortable feeling of fear. Why is it that humans, known pioneers and explorers, are afraid when seeing something new? What’s even more surprising is that we keep driving to explore even when we’re scared. That somehow we overcome our fear in an effort to learn more.

Given Freud’s definition of the uncanny, how can we create something that is uncanny? How can something be created that defies what we believe in? I think the perfect uncanny creation can be found in a 2001 japanese horror movie called Kairo. The scene can be found here (https://www.youtube.com/watch?v=QYs87-kDXwg). It shows a character going into a dimly lit basement and encountering a ghost. What makes this scene so terrifying is because it follows Freud and Hoffman’s formula of the uncanny. First, Kurosawa, the director, makes us discover the ghost by placing it way in the background and shrouding it in darkness. He makes us have to willingly perceive it, rather than shoving it in our face. By revealing the ghost during the second shot of that wall, he adds the element of uncertainty. We start to wonder whether it was there the whole time or it suddenly appeared. At this moment we start to empathize with Nathanael. We start to understand how he felt for the entire story, never sure of what’s real and what’s not real. In addition to this, Kurosawa doesn’t show the full ghost at first, obscuring the ghost’s face and upper half. We’re left wondering if it’s a woman, a doll, or something entirely different. Then it starts its eerie, unnatural walk. We’ve never seen a human walk the way she does, almost seeming like a puppet mimicking a human’s walk. The ghost’s pace is painfully slow, until it suddenly dips down into the light and we get a glimpse of its pale face. During this scene, we’re painfully subjected to witness everything. The camera stays completely still and there’s no sudden movements. Still unsure as to exactly what the shrouded figure is and what it wants, we follow the character as he scurries behind the couch. During this scene we’re able to see the ghost the entire time.  That is, until Kurosawa, just like the Sandman, robs us of our eyes. Right when the ghost is upon us, he shifts the camera down to below the couch. We’re suddenly unable to see the ghost and are limited to a very narrow point of view. At this moment, we find ourselves desperately wanting to see everything again even if it frightens us. That which we can see is way less scarier than that which we cannot. We’re left painfully staring at the floor for what feels like an eternity, until we can finally see the ghost’s hands creep over the top. Finally, we get to see the ghost’s blank face as it slowly peeks over. Even then we are left with uncertainty about the ghost, as its face remains completely still.

Sorry professor, as this was a little different from a reflection of the readings, but reading Freud and the Sandman really helped me understand why this scene is so effective. All of the horror elements and the buildup are very similar to the Sandman and it makes me wonder if the director knew of these works when creating this film.
Kenneth Gross describes the puppet as a paradoxical creature in nature, noting that just like us, they have no clear-cut definitions. The puppet lives in a world of uncertainty, where meaning is only given to it by the puppeteer and the audience. The puppet is both human and inhuman. It serves as a reflection of human nature, while at the same time being a lifeless, cold object. Though it is an inanimate object, the puppet can express things even humans themselves cannot. They are creepy, uncanny objects, yet at the same time, they are beautiful, handcrafted works of art. Even the initial purpose of puppets is a paradox in of itself, created to breathe new life into those who have passed. Gross’ fascination with puppets comes from the inability to define a puppet. I would argue that this point of view could be extended to pretty much anything created by humans and the best way to show this is to use an example.
	Let’s take a piece of paper. A plain, ordinary object that can take on many meanings, depending on how we choose to see it. A piece of paper can be currency, serving as the driving force for most of our lives. With a few words on it, a lifeless piece of paper can transport the reader into new worlds and ignite the human imagination, breathing life into characters and stories. Origami masters transform pieces of paper into beautifully delicate works of art through some thoughtful folds and creases. Even the very creation of paper itself is reflective of human nature: the want and need to share ideas with friends and generations to come. I believe that the statement Gross is making with this work is to show that there are no definites when it comes to me. Nothing is black and white. The meaning and features of anything in the world come from human interpretation, which is never the same from person to person and is constantly shifting and evolving.
	One idea that really caught my attention while reading is:
Puppets also have often been asked to say things or show things otherwise not permitted; it is a theatrical mode whose words and actions are more able to slip under the radar of official censorship, something too trivial to be taken quite seriously by the authorities (though in practice puppet theater could be just as subject to restriction as the theater of human actors). (Gross p. 25)
I love this use of puppets and I think it shows how human puppets can be. In my opinion, the most human trait is to always fight for what’s right and express what you think. It seems that for some, puppetry can be a window into what they really want to say, removing their personal constraints by displacing the message onto the puppet. In this way puppetry reminds me a lot of music where the puppeteer/artist is able to express raw emotion through their medium. In my opinion this is one of the purest forms of art and it definitely has the most meaning to me. Leading back to Gross’ paradox even this idea can be given different meanings by different people. On one side of the coin, you can view it as a unique way to spread your ideals. On the censor’s side, you can see it as a gross spreading of misinformation.
As an engineer, what I find most fascinating about Jessica Riskin’s essay is that it beautifully captures one of the major drives in robotics. Since the dawn of computers, some engineers have tried to tackle the ultimate challenge: to mimic and create life.  We see this effort from Vaucanson’s various machines and automata. First with the titular defecating duck, he attempted to mimic the digestive processes of a live animal. Then with his automata, he tried to mechanically replicate certain human actions such as making music. With his work, Vaucanson tries to blur the line between life and machine. With his flute-playing automaton, he tries to tackle the most human thing he could think of: the creation of art. The success of the automaton made society question what is truly human. Is it the actions we perform and the things we create or is it something innate within us? At one point does the automaton become a human? This essay really made me wonder why it is we choose to make robots that resemble living things. Vaucanson’s work is not unique in trying to mimic life. Even today we have companies such as Boston Dynamics, creating robots that successfully replicate the mechanics of different living things such as dogs and humans. Their work is groundbreaking in computer vision, AI, and mechanics. They’ve even created responsive robots that can handle external stimuli such as being kicked or shoved, regaining their balance after getting knocked around.

The question that I want to dive into is why is it that we are so interested in trying to mimic life? One of the reasons why I think this is the case is because we have something so complex right under our noses that we barely understand: our own bodies. We’ve lived with it everyday of our existence but we’re still mystified by so many things, especially with the brain. I believe that we try to build machines that imitate us in order to better understand our bodies and how they function. Vaucanson shows this by creating a duck with a digestive process that resembles a living duck. He also used the flute-playing robot to discover the mechanics between how a flute and other instruments work. By mimicking, Vaucanson actually discovered how some processes actually work. Boston Dynamic’s self-correcting robots try to understand how our bodies react to physical stimuli, recreating how our bodies unconsciously correct and self-balance.

Another reason why I think we try to replicate life is religious in nature. Although I am not religious, I can understand why some people would drive to create life. From my perspective, I believe these people are trying to become more like their creator when trying to replicate life.  To create life is inherently divine and to some it is the ultimate goal to become like their god/gods. There must also be a primal sense of joy when creating something semi-alive. It’s a similar feeling to when we have children. This could also explain why we tend to name our robots, as if they were our blood. It could be that the bodily response of successfully creating a robot is the same response that’s emitted when we see our children. Of course this theory should be taken with a grain of salt as I’m nowhere near qualified to speak about the pheromones and chemicals released when having a child, as I’ve never had a child and I have very little understanding of the human body. I think Freud, however, would have a field day analyzing the psychology and the motivations behind robots outside of assisting humans.

I believe that Haraway’s main goal with her essay is to push forward the idea of destroying long established ideas of One and the Other. She believes that the destruction of taxonomies such as self and other, right and wrong, and especially gender are the key to progressing as a society. She argues that these definitions, birthed from Western culture, resulted in an antagonistic, clashing culture. However, recent technological innovations and science fiction have started to challenge these strict distinctions. The cyborg is a perfect example of this, blurring the line between nature and technology as well as the line between human and inhuman. The idea of the cyborg forces society to reevaluate its black and white perspective on life and society, starting the process of potentially changing our ideals for the better. One such way that it could change and is changing is the destruction of gender. As historically relevant as it may be, it is probably the best to destroy gender roles and the idea of gender. Haraway believes this to be the key to true feminism.

This essay made me wonder how relevant religion is with the rise of these taxonomies. A lot of these strict distinctions can be found in western Abrahamic religions, especially Christianity. The idea of right vs. wrong, heaven vs. hell, and God vs. the Devil is seen all over scripture, and these religions have been one of the main driving forces of Western civilization. Perhaps these religions are the reason for the issues described in Haraway’s essay. The best way to see if this is the case is probably to examine the differences in between those religions and other religions that don’t focus too much on differences and distinctions. Although, it is quite ironic that to examine the impact of religions focused on differences I choose to look at different religions. Perhaps it is due to me being raised in a culture focused on differences.

From my experience, it seems that Asian culture seems much less driven by differences and the religion seems to reflect that as well. Asian culture in general seems to be more revolved in improving the self and the family rather than right and wrong. This idea can be seen in the dominant religions that emerged from the East, such as Buddhism. Buddhism focuses on mindfulness and self-actualization, while Western religions rely on two feuding sides. It would be very interesting to see how this idea applies to African cultures, but, since I don’t really know much about religion in general, I don’t feel confident in being able to accurately represent other culture’s ideas.

One of the ideas that really popped out of me in the chapter is the over-sexualization of female robots in science fiction. The magnitude of the over-sexualization hadn’t really occurred to me until I read the chapter and really thought about it. Some of the most revered science fiction movies are filled with this needless sexualization of the female character. Take for instance Ghost in the Shell, a movie that has inspired films such as The Matrix. The main character is Motoko Kusanagi, a cyborg public security agent, who takes on a notorious hacker. In the movie Motoko is often depicted in skin tight suits and without clothes. If we compare Motoko to something like Robocop, we see that Motoko is a sexual figure in addition to being a cyborg police officer while Robocop is just a police officer. In Bladerunner 2049, K is a replicant cop hunting other replicants down while his partner, Joi, is an AI wife for sale, shown nude in an advertisement.  I think a great commentary on this is Ex Machina. In Ex Machina the CEO of a gigantic search engine tries to design an AI capable of passing the Turing test. An engineer at his company wins a trip to visit the CEO and test out and interact with the robot. As the engineer talks to the robot, he discovers that the CEO has been abusing the previous iterations of the AI sexually and emotionally; the engineer finding various sex robots in the CEO’s bedroom and discovering that the only other “person” in the house is actually a robot that is constantly yelled out by the CEO. The CEO represents a man with all of the resources in the world and, before creating a sentient AI, he creates sex robots. These are just some examples in movies, but popular culture is littered with them. It should be noted that these are very generalized simplifications of these works of art. In some cases, the sexualization is intentional in order to provide so commentary on society, as it is in Ghost in the Shell. I have also not seen Ghost in the Shell personally; however, I thought it would be good to include because of its mention in the chapter and my vague familiarity with it.

This is often a problem in video games as well. In video games, female characters are often over-sexualized when compared to male characters. In most cases, male characters are often heavily armored while female characters are much less conservative. This has become such a problem that it has pushed some female gamers away from gaming and has caused some men to be much more misogynistic. I’m not really sure how it came to be this way. It could be that in the beginning, computer games were a much more male dominated market and companies tried to market toward this audience, causing the sexualization of female characters. It could also just be a trend derived from movies, noting that movies with these character archetypes sell more and are seen in more popular movies. Regardless of the origin, it has made the community unbearable for some women. I’ve personally seen guys berate women for simply playing the video game, telling them that “they’re only doing it for attention.” It’s honestly a very sad sight to see and the result is a toxic side to a very popular community.

Asimov’s “The Runaround” is a perfect example of the perils of trying to create super-intelligent AI. This piece shows that the intent of creating super-intelligent AI with the purpose of controlling it is futile. No matter which way you look at the problem, there is either too much to account for or too many possible contradictions. When creating a super-intelligent AI, or any AI for that matter, there needs to be a set heuristic for it to make decisions. This heuristic will dictate every decision that the AI may need to make. The first approach to tackling this heuristic is to set a few broad rules, as they do in “The Runaround”, and having the robot adapt and make decisions based on feedback. This allows your AI to be more malleable and fluid in their decision making, at the cost of having less control. This means your AI can potentially react to novel decisions on the fly based on previous experiences, but it could react poorly and make the wrong decision. Another problem with this approach is that it will require a lot of supervision, a lot of feedback as to whether the decisions they made were correct or not. This would take a lot of time and resources, while also not guaranteeing a proficient enough AI. Another issue is that the lack of restrictions could cause public distrust in the AI (“It’s gonna take over the world”). The other solution is to make a very complex heuristic with many many rules for as many situations as you can think of. This would create a very controlled AI, where many of the decisions have already been thought through. This type of heuristic would result in a more trustworthy AI, as many of the decisions have been thought through by a human and there wouldn’t be much improvisation. The issue with this type of approach is that your AI becomes very rigid, if a new novel problem comes, it may be hard to determine what the AI would do. In addition to this, it is impossible to account for enough scenarios to add to the heuristic to make it useful as a general purpose AI. As you add more and more rules, it becomes more and more likely that there will be a contradiction. “The Runaround” shows this rule issue in a situation where only 3 golden rules are present. Now if we were to add even more, the situation occurring in this short story would happen much more frequently. There would be countless bugs and it would be impossible to resolve all of them.

This is only one layer of the issue as well. Regardless of the approach there needs to be an immense trust in the people that make the heuristic. The heuristic is basically a model of what the programmer, the person behind the machine, believes is the best decision or most important factors. If it is left to someone nefarious, the AI will model their views which could potentially be life threatening.  Elon Musk actually talks about this in a Werner Herzog movie called “Lo and Behold.” He says that he fears the creators the most when it comes to sentient AIs. Even in a perfect scenario, where the model group of people select the factors important to the heuristic, there will always be a mistake in it. In some situations, the heuristic will not actually give the best result, hence why it’s called a heuristic in the first place. This is why I believe that the idea of trying to create a sentient AI to use as a tool is pretty misguided. I believe that a sentient AI should be created just to observe and see what it does and how it interacts with people.

This particular piece on drones really had me thinking a lot about my own career aspirations and my academic pursuits. It made me think about how many of the engineering jobs in the United States are primarily from federal defense contractors. So many inventions and the engineering feats have only happened because of the military. The Internet, for example, was created for communication in the military. So much research funding is only available to engineers who will use some part of their research to essentially find a better way of killing people. It’s such a broken part of our system to motivate engineering in the direction of violence instead of trying to better society, taking some of the brightest minds and using them for evil. Early on in my Cooper days, I decided that I would do my best to not directly or indirectly contribute my work to help killing people. The worst thing would be to take part in a machine that kills people that will never be buried.

In her book, Rhee describes the effect of drones on the modern landscape of war. One of the most surprising things to me was the fact about how the US determines what is and what isn’t a military combatant. She says this about the subject: “The United States considers any military-aged male (MAM) killed in a drone strike to be an enemy combatant, unless posthumous evidence to the contrary is provided. It should be noted that the United States does not investigate the identities of those killed by its drone missiles.”  This way of denying culpability in order to justify the use of drones and current military tactics is just utterly revolting. To misuse statistics and spread obvious misinformation so that they don’t know your killing innocent children and civilians is a heinous crime against all humankind. Tactics like this remind me of how the US looks to people in countries like Yemen and Afghanistan, countries that are being hit with these unseen drone strikes everyday. To them the US isn’t a bastion of hope. To them the US is an oppressive military regime that couldn’t care less about their lives because of the color of their skin. An unseen threat has determined that their children must die because of the potential “threat” they might be in the future.

Another topic that Rhee discusses is the notion of the Other and it’s use to dehumanize an enemy. The dehumanization of a perceived opposition is so common in the bigotry that plagues the US. So often when you hear people who pride themselves on hate, you hear them refer to the opposition as if they can no longer empathize and envision themselves as the people they hate. They’ve somehow along the way chosen to no longer see them as people, but rather see them as a lesser being. This same mindset is used in the military drones we have today. I remember teaching a class to high school students in the summer about STEM subjects. During a discussion on ethics, the ethicality of military research and technology came up. I remember hearing one of the students' responses in justifying engineering innovations for war. They said something along the lines of “it is necessary for the US to eliminate our threats.” Here we have a high school student talking about people, real people, and labeling them simply as “threats” just because they happen to be born in a different country. This dehumanization of children in the mind of a high schooler in the US shows the deep prejudices underlying our culture. A person who isn’t even an adult yet has come to believe that it is okay to bomb civilians who have no way to defend themselves. Of course, this student probably didn’t understand the magnitude of their statement, but it still shocked me.

Mark O’Connell’s “A Visitation” chapter in To Be a Human centers around O’Connells visit to a body preservation facility known as Alcor. Alcor offers the unique service of freezing and preserving the bodies of those who have been pronounced clinically dead in the hopes that technology will eventually progress to the point where they may be brought back to life. Alcor believes in the transhumanist idea of augmenting the human body to overwrite the human condition and essentially become immortal. While reading this piece, I didn’t realize for the first couple of pages that Alcor was a real company. I thought it was a piece of science fiction. It was only until I Google’d it did I realize that it was an actual thing and people were true believers in this. In my opinion, I don’t really buy into the whole idea of Alcor. I think it’s quite manipulative to bait people into thinking that technology will somehow progress to the point where they can be revived and live indefinitely. They’re essentially exploiting people who are too scared to die and stealing money from the families they leave behind. I guess that it’s kind of a fundamental fear of transhumanists, the fear of death. This fear of death pushes them to believe that they will overcome death by merging with technology. I think this fear kind of weirdly ties the transhumanist movement to religion. Much like the transhumanist movement, religions also tend to appeal to those who fear death by promising an afterlife or some other form of life beyond death. Of course this I’m not trying to boil down religions to this one simple belief. I also found this piece a little funny because the entire time he was describing the process of preserving the bodies, I could only picture the floating heads in Futurama. I can only imagine how these patients would feel if the afterlife they were promised was to be floating heads in jars stuck in a museum whose sole purpose is to entertain guests. If this were the only way to preserve their life, I doubt they would consider it an eternal life, let alone a very worthwhile investment.

“Mere Machines” centers around O’Connell’s visit to a DARPA convention, a convention that showcases the inventions and innovations of a research agency of the Department of Defense. I found this chapter quite hard to follow and engage with. Much like the convention, O’Connell seemed to jump around from idea to idea a lot while not really engaging heavily with one. I guess it is the appropriate strategy if he would like to get through the entire convention and it also serves as a parallel of what he experienced while walking through the convention, but it still made it hard to engage nonetheless. One experience that I really liked in the chapter was when he came across a small stand for a company named Softbank Robotics. He describes a unique interaction between a representative, a robot, and a little girl. The representative repeatedly tries to tell the robot to give the little girl a hug, but every time the robot can’t understand what the representative wants it to do. All this is happening while the little girl is cowering behind her father, too afraid to approach the robot. This interaction beautifully encapsulates the fear of technology. We, as humans, are willing to let robots service us by driving us and by performing surgery on us, but, as soon as a robot tries to emulate a core human action like emotional intelligence, something innately in us tells us to be wary of it. We are much more willing to let a robot lift us, like in an elevator, than a robot give us a hug. I think it might have something to do with the fear of replacement that comes with robots attaining true intelligence. That we as humans believe that emotions are the one thing that separates us from these highly advanced robots that we see today, and, as soon as that final barrier is approached upon, it finally sinks in that we might not be too different from the machines we create.

