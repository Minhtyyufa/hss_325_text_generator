Kenneth Gross, in his essay, Puppet, roots his understanding of the puppet in relation to what is generally accepted as human. The ability to surpass the physical limitations of the human body and the imagery not found in the real world are two of the abilities of the puppet that transcend the human reality, but these two characteristics can be used to define other mediums of entertainment such as animation or literature. What fascinated me though was Gross’s likelihood to liken the unique features of the puppet to the very human experience of childhood, specifically the puppet’s memory, freedom, and potential.

             By memory, I mean the memories and feelings of sentimentality associated with the puppet. Gross, with these memories in mind early in Chapter 1, characterizes the puppets as “relics, souvenirs of someone else’s childhood, and so a little senseless, out of phase, abandoned, waiting to be taken up, their fixed smiles carrying some other knowledge, oddly clairvoyant in their muteness.” (19) The puppet, simply in its existence and use, conjure up memories to the observer, unaware of the memories the puppet itself has from creation and performance. The reality of these sentimental memories can even be toyed with through the medium of the puppet such as in my favorite performance theme from chapter six, “Lessons for a shadow: How to creep up a wall. How to watch from behind a door. How to fall suddenly across a page. How to stretch out along the ground. How to disappear in darkness. How to inseminate the light” (84) Within this performance of the puppet, feelings from childhood such as the learning a plethora of things for the first time are reexperienced in contexts that are both familiar and alien, and the puppet portrays sentimentality that transcends human limitations.

            It is these limitations that puppets continuously transcend, embodying a childlike freedom unbound by society. Gross remarks that “puppets also have often been asked to say things or show things otherwise not permitted” (23). Like a child that can say anything due to its lack of maturity, the puppet similarly able to say anything but due to its lack of humanity. With humanity referring to a mature adult, the puppet and the child enjoy this freedom due to their small stature, and Gross acknowledges this saying that “the very diminutiveness that seems to put an object or moment at risk is also the source of its power, even as its small size makes it a thing the world is liable to violate, misapprehend, or embarrass. (48) It is based in this power that gives the puppet and the child freedom as well as potential.

            This potential of the puppet is very similar to that of a child, the capacity to be any identity. Gross states that “every puppet—from the crudest Punch to the most delicate dancing marionette—has a potential for being at once devil and sorcerer, mocker and teacher.” (29) A child ability for metamorphosis is similar to the use of puppets in whatever role it is needed for in the moment, but what is interesting is how Gross sees this potential as decay. He argues that “human beings inevitably become more dead, more wooden than puppets.” (63) In turn, the puppet becomes the ideal symbol for humanity, rather than a regression of it.

            Ultimately to explain what is essential to the puppet is to explain what is essential to the human, and to declare that the humanity as represented by a child is the optimal state of it, is a grand assumption. Is the freedom, sentimentality, and potential present within the child and the puppet truly limitless? How can this be if Gross’s characterization of the child and the puppet are rooted in its relation to the reality of society, hinting at the finite nature. Furthermore, Gross’s characterization of the soul of the human and the puppet can also be used to refute this characterization, for to be able to mourn for the death of the human and the puppet, it is in respect to the potential that is realized by the soul.

  A substantial about of modern politics continues to take place on social media, citing truth and fact as the basis for many different arguments. In Chapter 10, Gross explores the idea of the puppet as an avatar through a discussion about our shadows and their relation to what is true. Specifically exploring the idea of the shadow puppet, he remarks that “the shadows are taken as avatars of the really real. They mark the presence of truth rather than that which conceals or takes the place of truth.” (120) The shadows themselves are vague and often misleading, affecting our perceptions of each other, and they often point towards a reality proportional to its size both literally and figuratively.

            Two situations in which this perception of the avatar comes into mind are the Black Mirror episodes “Nosedive” and “Be Right Back”. “Nosedive” takes place in a utopian society in which social media ratings determine everything from what someone’s social status is to their priority in making purchases. It is a tragic story of Lacie, who in seeking to raise her social media standing so that she can attain a discount for her dream house, destroys her own ratings. In this process though, she meets another woman, who chooses to leave the social media lifestyle in order to attempt to see people for who they really are. Following the footsteps of this woman, Lacie finds a sense of social freedom, despite ending up in a jail cell. “Nosedive” brings up interesting questions regarding the nature of our modern-day avatars. Do our shadows and avatars represent our freedom, or do they confine us to upholding them? Do they serve as an unnecessary intermediary for interaction?

“Be Right Back” takes this idea of the avatar being a representation of the person and turns it on its head. What if the avatar was all we had left? Gross explores this idea a little bit in talking about the sentimentality of puppets and the history of it, but in this episode, the social media is used to bring someone back from the dead. Martha, mourning the death of her boyfriend Ash, decides to subscribe to a service that replicates his speech and personality in a chat bot. Initially pleased with this, Martha upgrades to replicate his whole body using this information, creating a physical avatar or puppet for Ash. Ultimately, she feels that something is wrong, that although this avatar looks and talks like him, it is different. In the context of Gross’s ideas, it seems as if this puppet has a soul of its own, despite being preprogrammed. The feeling of watching this was like watching the shadow puppets dance, with special link to the spiritual. This episode and the idea of the shadow puppets seem to make the case that these avatars can represent the users to some extent but are somehow more than just the representation.

            One example of how these shadows are more than what they seem is within the physical realm; literally, shadows can raise awareness for conditions that must be taken into consideration such as the recent snowstorm. I had brought up to a friend that I was stuck in the house because of the snowstorm and that I didn’t take it into account before planning my day. She had responded, “When did you realize that, when it was dark outside?” I was initially very confused at what she was talking about, but she had explained to me that the mornings feel darker because of the light that gets blocked by the snow on people’s houses. Thinking back now, the shadow could have been anything, but regardless, it would have represented some deviation from the ideal sunny morning.

            The effect and possible vagueness with the shadow is evident; metaphorically though, the shadows of ourselves on social media point towards our perceived realities and truths about the world around us. “Fake News” has become such a commonplace term, and there are examples of both political parties taking place in playing with the reach of avatars through censorship and coverage. Black Mirror’s stories seem to go with the narrative that this perception can be used and changed, and it is possible to affect this the avatars and subsequently the truth. In a society where we believe this truth, and the media is controlled, does that make us the puppets?

            As I said in class, my first thoughts regarding the nature of what is “uncanny” were very limited. I had thought that uncanny was another word for superhuman, linking the uncanny to something extraordinary, yet human. Both Freud and Hoffman, in “The Uncanny” and “The Sandman” respectively, changed my preconceived notions on the meaning of Uncanny.

The moments that stood out to me as the most uncanny in E.T.A. Hoffman’s “The Sandman” were centered around Olympia. Throughout the story, Olympia only says ‘Ah, ah!’, and I must admit I had thought it originally was a response that was not too abnormal. After all, it was mentioned that she had limited interaction with the world, and Nathaniel’s special attraction towards her was something that made me overlook the limited response. Her described beauty was special, but in contrast to young Nathaniel’s description and experience with the Sandman, it seemed more believable. Despite my initial reactions though, it was the repetition present in Nathaniel’s experience with her that could only really be called uncanny. His infatuation with her, declaring his love despite Olympia continuing to say nothing but ‘Ah, ah!’ became something very creepy after many repetitions of this same response. The repetition calling into question Nathaniel’s eyes, a symbol of his experience with the Sandman, set up this uncanny dichotomy between sanity and madness, that held throughout the entire story.

Freud, analyzing this uncanniness gives conclusions of what he believes is behind the uncanniness. Many of these conclusions had a place within the “Sandman”, but one that I noticed instantly was his statement that “As soon as something actually happens in our lives which seems to support the old, discarded beliefs, we get a feeling of the uncanny;” (17) Nathaniel’s old discarded beliefs about the sandman came back just when he was about to live the rest of his life with Clara, and he must have felt an uncanny feeling moments before his death. Is the idea of the uncanny deeply linked to a madness within familiarity, “the unheimlich is what was once heimisch”?

This specific feeling regarding the uncanny in something that was once familiar made me remember “House of the Marionettes”, a manga written by prolific horror mangaka, Junji Ito. Quite short, I had been recommended to me only slightly before reading Freud or Hoffman, and I think within the horror it captures the uncanny familiarity completely. To summarize, it is about a boy who’s family is a group of travelling puppeteers. Deeply invested in the meaning of the puppets, his brother and father disputed over whether the human was in control of the puppet or vice versa. Years later, the boy is invited to his brother’s house located in what the boy would most likely consider his hometown, and he is surprised to see that the brother has decided to prove that puppets are in control by becoming a puppet himself. To elaborate, the brother connected strings all over his body and hired people to move him. The circumstances at the house hint towards ideas from Gross, as these puppets seem to defy human limitations, but by the end of the story, the boy realizes that his brother in the house was never human to begin with. The madness that possibly encapsulated this boy, and the constant repetition of the theory about who controls who brings questions of control to the forefront. It tackles both the supernatural aspect of the uncanny, its possible roots outside of humanity, and the theme of familiarity both in the familial sense and the situational sense. Freud also brings up some of the themes relevant here such as the illusion of free will and the intellectual uncertainty on what is alive.

I do not have a complete understanding of what the uncanny is yet though, and I don’t think I will. Some ideas of Freud’s particularly confused me. What exactly does the castration complex have to do with uncanniness? I thought Nathaniel’s fear was based out of a love for his father. I understand how primitive beliefs, or previous beliefs, could define the uncanny, but I am not really sure why this can be extended to infantile beliefs (17).

My initial reaction to the writing was filled with struggle and irony: struggle in piecing together Haraway’s various one liners throughout the manifesto and irony that the formatting of her writing very much so blurred her thoughts on the matter together. I will say though that I am very glad I was able to make it through as, Haraway ends her manifesto with statements of clarity about blur that tie much of the manifesto together. Saying that “Cyborg imagery can suggest a way out of the maze of dualisms in which we have explained our bodies and our tools to ourselves”, Haraway ties the knot tight between her discussions of technology and feminism. (67)

            Using this argument of blurring dualisms and boundaries, Haraway is surprisingly hard on the capitalist/patriarchal west, and I was particularly shocked by her numerous callouts against the Christian faith. With biology continuing to blur the line between what is human and animal, she makes a very early assertion that “teaching modern Christian creationism should be fought as a form of child abuse” (10). As a Christian studying STEM, I never particularly saw this as an issue, but I do understand how her characterization of the cyborg directly goes against many different biblical distinctions of people, one examples of which being the Israelites, referred to as God’s people. At the same time though, the Bible is full of numerous dualisms that would have helped her make her point. How do we distinguish between ideologies of predestination and free will, salvation by works or by faith alone, the mystery of the Holy Trinity as three distinct beings within one? I do not particularly know the answer to each of these scenarios, nor do I fully understand the whole discussion for each, but at the very least these are examples of cyborg like blurs that could have been used. As a result, it was part of some sentiment that Haraway’s political affiliation and focus on feminism took precedence over her discussion of the cyborg.

            Haraway spends a great among of time talking about communications engineering, which happens to be my personal area of enjoyment within the larger electrical engineering, yet some of her arguments about technology pose practical problems. She makes numerous references to the C3I military model of communication, and towards the end of the manifesto she say that “Feminist cyborg stories have the task of recoding communication and intelligence to subvert command and control.” (56) In theory this kind of system that subverts command and control sounds ideal; maybe the closest analogy in technological terms would be an internet that is purely based on peer to peer connections rather than on larger servers that have the most control and access. I knew immediately though that especially in a military application this would be impossible. Haraway explains further, “That is why cyborg politics insist on noise and advocate pollution, rejoicing in the illegitimate fusions of animal and machine.” (57) Without organization and control, communication in this sense just looks like noise, and if a noise floor gets large enough, people who want to communicate with intentionality and control simply lose the ability to do so. It would be like trying to have a conversation on opposite sides of a crowed, loud room. So I wonder how this cyborg blur can be done in practice, usually with generality comes loss of specificity, but there may be ways around it. Today, there exist ways in communications engineering to transmit signals as noise over a wide spectrum of frequencies and still be able to decode it; it is what is known as our 3G and 4G technology. Although I know it is possible in the technological sense, I am not sure this is one analogy that generalizes very well.

The idea of the tool is something that Kakoudaki explores in the earlier part of this chapter on the mechanical body, and a particular concept that was of interest to me was the idea of the tool intertwined with ideas of control and limitation. Typically, I would have considered tools as completely under the control of the person, something to be used to bypass limitations of ability. Kakoudaki subverts this responding, “This set of conceptual interactions reveals an alternative to the sense of mastery we might experience with tools: if tool use implies conscious control, the body’s own mechanicity enacts a different kind of control over the self, “bottom up,” as it were, instead of “top down.” (72) The idea of “bottom up” control from tools surprised me. As an initial example, when I think of a hammer, it is not like the first thing I think about is that the hammer now imposes new limitations on what I can and cannot do, but it is true. Having a hammer as an extension of my current ability limits my ability to do other things except for hammer but thinking about tools in this way still inherently give myself the control over what I am doing. By extending the thought of what is a tool to encompass our own bodies, it is possible to easily understand much higher levels of feedback and symbiosis from the person and their body. The body’s mechanicity impose many requirements on the way we live; all of our basic needs like food, water, and shelter are all required because of this mechanicity. A particular example of this that Kakoudaki brings up is sexual desire, but this is probably the area that I have the most questions. To what extent does sexual desire stem from the mechanical, and to what extent do people have top-down control over that desire? This might be the exactly why she uses this example to prove both feedback between the top-down and bottom-up control. It is also a way to bring up the question of where the mind ends and where the body begins.

These questions then have answers to some extent within a Cartesian and Aristotelian thought process. Aristotle in particular focuses on the “explanatory power of sequence and causality.” (97) He also “traces the motions of natural bodies to the unmoved mover” (98). Between our conversations stemming from the puppet, to the automaton, and now to the cyborg and robot, there seems to be a distinctly spiritual aspect and explanation for all sources of the uncanny. It very much so seems like that through these unique, yet very intertwined topics, we’re actually exploring themes like control and the essence of the soul. I was surprised to see electricity join the ranks of “other invisible, ineffable, and permeating forces such as faith, sexual attraction, inspiration, the imagination, and the will.” (108) As an invisible force to the naked eye, it is like the unmoved mover to the machines that we have been talking about, but even electricity has mystical/spiritual properties to it. On one hand, Kakoudaki makes remarks about how, in its early use, electricity was seen as otherworldly. On the other hand, the specificity of the properties of electricity in a strictly physical and chemical aspect with conductors and semiconductors point towards another Aristotelian unmoved mover; who could have created such perfect conditions for use?


Both Capek’s play “R.u.r.” and Atanasoski and Vora's "Technoliberalism and Automation" use the idea of the Robot as a mechanism to tackle questions of dignity and hierarchy. In the first act of “R.u.r”, I was quite amused at Helena’s confusion at the distinction between robots and humans. The directors of the factory respond by marking the distinction between the humans and the robots by what is on the inside, with the robots being more mechanical than humans. There is even a focus on dissection in Act 3 that calls back to this belief that robots are different on the inside. I find it fascinating because Helena’s continuous reaction even after 10 years is an inherently spiritual one; she argues that the robots have the capacity for the soul on the inside. I continue to wonder at what point our being begins and ends. What one describes as consciousness and soul could be mechanically described as the firing of electrical signals in our neurons. The terminology of inside and outside as a dualism used to separate the inanimate and animate is a boundary that becomes completely broken as the robots show what Alquist believes is the capacity for soul: altruism.

               How can the definition of what is human be so focused on the soul and the care of others if the idea of the robot under Technoliberalism is so deeply intertwined with domination and hierarchy? In Asimov’s 1942 short story “Runaround”, the three laws of robotics each show that the life of the human is more important and valuable. Atanasoski and Vora would argue that the robot is viewed in the same manner; by perceiving the robot as less than human, it can be treated as such. While the appeal of free labor and high levels of productions are there, treating anything as less than human becomes a preservation of the same actions and views that were evident in the institutions of slavery and racism.

               I am not very sure how to respond to this. My first thought is a biblical one. Nana’s spiritual aversion to the robots from not wanting to play God is not about the use of the robots but rather the creation of them in general. With the greatest commandment calling each human to “Love your neighbor as yourself”, that love can be argued for if a person is not human. (Matthew 22:39) At the same time, God “formed a man from the dust of the ground and breathed into his nostrils the breath of life, and the man became a living being.” (Genesis 2:7). Made from the ground, the form of the man at birth is then an inherently mechanical one, and as each human is born, are they then given the soul through this breath of life? If so, how is this any different from the inherently mechanical being of the robots? How would we even know whether this breath of life/consciousness/soul is given to robots in the same way?

               The distinction between the soulful and the soulless is a differentiating factor that can only be classified unsurely. While the end of R.u.r. does focus on dissection and what is on the inside, I do not think anyone would be able to dissect far enough to find the soul. Or it may be the kind of situation like Heisenberg’s uncertainty principle where you cannot know there is a soul without destroying it entirely. Again though, idea of the robot seems to be very deeply based its relation to what is human, and I think Asimov and Vora would also agree that our idea of what is humane is deeply linked to our ideas of what is robot. If there is a perceivable differentiating factor, whether it is spiritual, physical, or anything else, I wonder how people would respond.

 Rhee seems to be making a push for a more humane cybernetic war and makes a clear cybernetic spectrum between the human (complex classification) and the machine. Likening classification to dehumanization, she argues, “These erasures – of ambiguity and uncertainty, materiality, complexity, and context – in the name of calculability continue on in drone processes in the form of dehumanizing classifications and misclassifications.” (142) Are these concepts really being erased in the machine, and to what extend do we really believe that we do not abstract away complexity in the name of classifications? What is “humane” is probably much closer to the cybernetic, to the machine, than Rhee brings us to believe.

            One of these areas in which we are close to the cybernetic is in our observation of people and the idea of focus. In the section “The Dehumanizing Limits of Drone Vision: Dronestagram and #NotaBugSplat”, Rhee brings up the “dehumanizing gaze” of the drone. (162) Humans are dehumanized by the drone, looking like bugs and insects from so high up, and as a result, drones “are not designed to identify humans” (162). My first reaction is that humans do the same exact thing daily. In New York City, people roaming the streets do not perceive each passerby, but hopefully humans have the capability for observational focus. Is this not something that drones are capable of too? Accurate zoom and modern face recognition technology are just two areas in which the machine is already able to approximate this humanization. At the same time, if we see the drone as a tool, as an extension of the body, how can we say this dehumanizing gaze is really a dehumanization. This classification or lack of focus, and the mistakes that go along with it, may be the most human aspect of the cybernetic.

            The focus on classification specifically is another aspect that blurs the line between the human and the machine. Essential to decision making, humans would not be able to function without classification. To make any decision we must choose one option out of infinitely many, and therefore, we must abstract away large amounts of information and possibilities to arrive at the choice we make. Machines do the same thing, approximating the continuous with the discrete, turning the infinity known as decision making into a finite number of smaller decisions.

            While this is not necessarily a scholarly kind of observation, the stereotype of engineers without social skills is a very fitting example for this. I found that specifically when solving problems, there is a tendency to discretize and organize decisions into viable steps, a very machine-like/algorithmic response. Some reactions to this response are not unlike Rhee’s, accusations of robotic nature or an inhumanness. Is the response the result of the nature of decisions, to pick one we must ignore the other? Are these classifications inhuman, or are they superhuman?

            If the answer is that these observations/classifications are in fact a very human response, then that recontextualizes the whole conversation on drones. Drones would then be a subjugated class. Their presence around the world would be no more frightening than the abundance of humans. A piece of pop culture that springs to mind is Star Wars, a universe in which drones are both seen as robots to be subjugated as well as companions. I know a final project will be tackling exactly that topic, and I am excited if the response to Rhee was anything similar.

            Max’s conversation with his advisor during for his dissertation was one of the highlights for me as I read through this exploration on cryonics. Her ghastly reaction to the idea of life after death was met with such a pragmatic response. Why are the practices of burial and cremation not met with the same disgust, and what influences our instinctive reactions for this disgust? The conversation brought back memories of our previous talks about the puppet and the uncanny; the idea of life after death might be sufficiently different and similar enough to human life to simulate that uncanny feeling.

            The discourse between Max and O’Connell makes that disconnect in the creation of the uncanny feeling much more apparent. Max presents the cryogenics very similarly to the way the military would see drones, an evolution of life that transcends the human capabilities or “weakness of the flesh” (38). Rather than the storage of corpses, cryogenics is portrayed as an extension of medicine, and again there is a discussion on how much cybernetic enhancement is required to allow someone to transcend themselves and become “Transhuman” or “Posthuman”, both words that seem to suggest that these people will become something that is human no longer. If or when the clients’ Hail Mary pass to transcend humanity actually works, it will be the Ship of Theseus thought experiment will come to fruition, and I guess we’ll be able to experimentally determine some necessities of personhood.

            Nevertheless, the Hail Mary pass of cryogenics and the idea of cyborgs transcending humanity continue to have inherently spiritual roots. The idea of being in control of our own destinies, each in our own Pascal’s wager situations whether that is regarding cryogenics or religion, is born of both hope and fear as the More family embodies.


Earlier in the chapter there is a focus on sympathy for the robots. Ultimately, this sympathy came from observing the different failures of each robot, so I was wondering if failure was a necessary part of the human condition. In the case of the robots, one could say that the failure was not theirs at all; each blunder was the mistake of the programmer/creator not accounting for enough within the design. Maybe failure is typically so associated with the process of learning and improving that seeing each robot fail brings them closer to what is human.

            Even if we were to be sympathetic to robots, I don’t think that they should have sympathy in the same way. Firstly, sympathy for robots is a stark contrast to some techno futurist ideas, for rather than continuing to subjugate the robots, they would be elevated to the status of personhood. But our ideas of personhood would not really work for these evolutionary heirs; they would probably have a different set of problems altogether. After all, “Robots don’t need toilet breaks, and drones don’t get tired, and neither are likely to form unions”. (120) Through this sympathy, Robots seem to have an identity completely formed by the human, with even the ideas of sympathy being so linked to what sympathy to a human should be.

            That being said, robots may not be too far off from the same kind of sympathy or being. Provided sufficient energy, some robots are already able to self-wind as Le Mettrie would say humans do (126). Something as trivial as a Roomba is already able to clean a house yet know when it needs to return home to charge in the same way humans would work a job and need breaks to eat. In this situation, we may have sympathy (or feelings of anger) towards a Roomba if it were to fail to charge, and so this capacity for failure is a marker for the difference in the degrees of freedom between the robot and the human. Just as a joint in a robot could seem more human with enough degrees of freedom like in a Boston Dynamics presentation, the capacity for a robot to fail is a hint towards the supposedly free will of humanity.